syntax = "proto3";

package biovalue.llm;

option go_package = "github.com/biovalue-ai/biovalue/proto/llmpb";

// LLM Bridge Service - Python 实现的 LLM 调用服务
service LLMBridge {
    // 单次推理
    rpc Infer(InferRequest) returns (InferResponse);
    
    // 流式推理
    rpc InferStream(InferRequest) returns (stream InferChunk);
    
    // 批量推理
    rpc InferBatch(InferBatchRequest) returns (InferBatchResponse);
    
    // 健康检查
    rpc HealthCheck(Empty) returns (HealthStatus);
}

message Empty {}

message InferRequest {
    string trace_id = 1;
    string agent_id = 2;
    string system_prompt = 3;
    string user_prompt = 4;
    repeated string image_paths = 5;
    repeated ContextChunk context = 6;
    InferConfig config = 7;
}

message ContextChunk {
    string content = 1;
    string source = 2;
    float relevance_score = 3;
}

message InferConfig {
    float temperature = 1;
    int32 max_tokens = 2;
    repeated string stop_sequences = 3;
    bool enable_tools = 4;
    repeated ToolDefinition tools = 5;
}

message ToolDefinition {
    string name = 1;
    string description = 2;
    string input_schema = 3;  // JSON Schema string
    string mcp_server = 4;
}

message InferResponse {
    string trace_id = 1;
    ResponseStatus status = 2;
    ThoughtChain thought = 3;
    ToolCall tool_call = 4;
    string final_answer = 5;
    UsageMetrics usage = 6;
    string error_message = 7;
}

message ThoughtChain {
    string reasoning = 1;
    string plan = 2;
    float confidence = 3;
}

message ToolCall {
    string tool_name = 1;
    string tool_input = 2;  // JSON string
    string mcp_server = 3;
}

message InferChunk {
    string trace_id = 1;
    ChunkType type = 2;
    string content = 3;
    bool is_final = 4;
}

enum ChunkType {
    CHUNK_TYPE_UNSPECIFIED = 0;
    CHUNK_TYPE_THOUGHT = 1;
    CHUNK_TYPE_TOOL_CALL = 2;
    CHUNK_TYPE_ANSWER = 3;
}

message InferBatchRequest {
    repeated InferRequest requests = 1;
    int32 max_concurrency = 2;
}

message InferBatchResponse {
    repeated InferResponse responses = 1;
    int64 total_duration_ms = 2;
}

enum ResponseStatus {
    RESPONSE_STATUS_UNSPECIFIED = 0;
    SUCCESS = 1;
    TOOL_REQUIRED = 2;
    VALIDATION_FAILED = 3;
    RATE_LIMITED = 4;
    ERROR = 5;
}

message UsageMetrics {
    int32 prompt_tokens = 1;
    int32 completion_tokens = 2;
    int32 total_tokens = 3;
    double cost_usd = 4;
    string model = 5;
    int64 latency_ms = 6;
}

message HealthStatus {
    bool healthy = 1;
    string version = 2;
    map<string, bool> dependencies = 3;
    int64 uptime_seconds = 4;
}

