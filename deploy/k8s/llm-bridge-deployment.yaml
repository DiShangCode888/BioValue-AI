# BioValue-AI LLM Bridge Deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: llm-bridge
  namespace: biovalue
  labels:
    app: llm-bridge
    app.kubernetes.io/name: llm-bridge
    app.kubernetes.io/component: llm
spec:
  replicas: 2
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
  selector:
    matchLabels:
      app: llm-bridge
  template:
    metadata:
      labels:
        app: llm-bridge
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "9090"
    spec:
      terminationGracePeriodSeconds: 30
      containers:
        - name: llm-bridge
          image: biovalue/llm-bridge:v1.0.0
          imagePullPolicy: IfNotPresent
          ports:
            - containerPort: 50051
              name: grpc
              protocol: TCP
            - containerPort: 9090
              name: metrics
              protocol: TCP
          env:
            - name: OPENAI_API_KEY
              valueFrom:
                secretKeyRef:
                  name: biovalue-secrets
                  key: openai-api-key
            - name: DEEPSEEK_API_KEY
              valueFrom:
                secretKeyRef:
                  name: biovalue-secrets
                  key: deepseek-api-key
                  optional: true
            - name: CONFIG_PATH
              value: "/app/config/config.yaml"
          resources:
            requests:
              cpu: "500m"
              memory: "512Mi"
            limits:
              cpu: "2000m"
              memory: "4Gi"
          livenessProbe:
            exec:
              command:
                - python
                - -c
                - "import grpc; grpc.channel_ready_future(grpc.insecure_channel('localhost:50051')).result(timeout=3)"
            initialDelaySeconds: 15
            periodSeconds: 20
            timeoutSeconds: 5
            failureThreshold: 3
          readinessProbe:
            exec:
              command:
                - python
                - -c
                - "import grpc; grpc.channel_ready_future(grpc.insecure_channel('localhost:50051')).result(timeout=3)"
            initialDelaySeconds: 10
            periodSeconds: 10
            timeoutSeconds: 3
            failureThreshold: 3
          volumeMounts:
            - name: config
              mountPath: /app/config
              readOnly: true
      volumes:
        - name: config
          configMap:
            name: biovalue-config
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - weight: 100
              podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app: llm-bridge
                topologyKey: kubernetes.io/hostname
---
# Service
apiVersion: v1
kind: Service
metadata:
  name: llm-bridge
  namespace: biovalue
  labels:
    app: llm-bridge
spec:
  type: ClusterIP
  ports:
    - port: 50051
      targetPort: 50051
      protocol: TCP
      name: grpc
    - port: 9090
      targetPort: 9090
      protocol: TCP
      name: metrics
  selector:
    app: llm-bridge
---
# HPA
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: llm-bridge-hpa
  namespace: biovalue
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: llm-bridge
  minReplicas: 2
  maxReplicas: 5
  metrics:
    - type: Resource
      resource:
        name: cpu
        target:
          type: Utilization
          averageUtilization: 70

